{
    "id": 8,
    "name": "Cross-Cultural Assessment of Bias and Health Communication in LLMs",
    "duration": "2022-2025",
    "contributors":[
        "Shao-Man Lee", "Mu-Ko Chou"
    ],
    "link": "",
    "brief_introduction": "This research project, Assessing Value Biases and Health Communication Effects of Generative Language Models from a Cross-Cultural Perspective, investigates cultural value biases embedded in generative AI health communication systems.",
    "introduction": " Beginning with COVID-19 communication analysis across 134 countries, the study systematically evaluates major language models (GPT-4, Gemini, Llama3, Mistral) across 23 countries on vaccine-related tasks, revealing significant performance variations across cultural dimensions. The research develops an AI cultural fairness governance framework distinguishing thin and thick fairness approaches, and establishes a Taiwan-localized evaluation benchmark incorporating multi-stakeholder perspectives and comprehensive local medical datasets for developing culturally sensitive health communication systems.Figure: Cross-Cultural Performance Analysis of Generative Language Models on Vaccine Issues (2024).Panel A: Cultural Bias Comparison; Panel B: Income-Culture Interaction Effects; Panel C: Cultural Values and Vaccine Attitudes",
    "photo":"project_8.png"
}